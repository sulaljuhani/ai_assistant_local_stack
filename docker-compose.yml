services:
  # ===========================================================================
  # LangGraph Multi-Agent API
  # ===========================================================================
  langgraph-agents:
    build:
      context: ./containers/langgraph-agents
      dockerfile: Dockerfile
    container_name: langgraph-agents
    restart: unless-stopped
    environment:
      # API Configuration
      API_HOST: ${API_HOST:-0.0.0.0}
      API_PORT: ${API_PORT:-8000}

      # LLM Provider (OpenAI/DeepSeek)
      LLM_PROVIDER: ${LLM_PROVIDER}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_BASE_URL: ${OPENAI_BASE_URL}
      OPENAI_MODEL: ${OPENAI_MODEL}

      # Embeddings (Ollama)
      OLLAMA_EMBED_URL: ${OLLAMA_EMBED_URL}
      OLLAMA_EMBED_MODEL: ${OLLAMA_EMBED_MODEL}

      # Database
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}

      # Redis
      REDIS_HOST: ${REDIS_HOST}
      REDIS_PORT: ${REDIS_PORT}

      # Qdrant
      QDRANT_HOST: ${QDRANT_HOST}
      QDRANT_PORT: ${QDRANT_PORT}

      # State Management
      STATE_PRUNING_ENABLED: ${STATE_PRUNING_ENABLED:-true}
      STATE_MAX_MESSAGES: ${STATE_MAX_MESSAGES:-20}
      STATE_TTL_SECONDS: ${STATE_TTL_SECONDS:-86400}

      # Other
      DEFAULT_USER_ID: ${DEFAULT_USER_ID}
      TZ: ${TZ:-UTC}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      CORS_ALLOWED_ORIGINS: ${CORS_ALLOWED_ORIGINS}
    ports:
      - "8000:8000"
    volumes:
      # Mount source code for live updates
      - ./containers/langgraph-agents:/app
      - ./vault:/app/vault
    networks:
      - ai-stack-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # Frontend WebUI
  # ===========================================================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: ai-stack-frontend
    restart: unless-stopped
    environment:
      # Backend API URL (internal Docker network)
      VITE_BACKEND_URL: ${VITE_BACKEND_URL:-http://langgraph-agents:8000}
    ports:
      - "${FRONTEND_PORT:-3001}:3001"
    networks:
      - ai-stack-network
    depends_on:
      - langgraph-agents
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001"]
      interval: 30s
      timeout: 3s
      retries: 3
    labels:
      - "com.centurylinklabs.watchtower.enable=true"

  # ===========================================================================
  # Open-WebUI Adapter (OpenAI-style shim to LangGraph)
  # ===========================================================================
  openwebui-adapter:
    build:
      context: ./openwebui/adapter
      dockerfile: Dockerfile
    container_name: openwebui-adapter
    restart: unless-stopped
    environment:
      LANGGRAPH_CHAT_URL: ${LANGGRAPH_CHAT_URL:-http://langgraph-agents:8000/chat}
      LANGGRAPH_API_KEY: ${LANGGRAPH_API_KEY:-}
      LANGGRAPH_USER_ID: ${DEFAULT_USER_ID:-00000000-0000-0000-0000-000000000001}
      OPENWEBUI_ADAPTER_API_KEY: ${OPENWEBUI_ADAPTER_API_KEY:-change_me}
      LANGGRAPH_REQUEST_TIMEOUT_SECONDS: ${LANGGRAPH_REQUEST_TIMEOUT_SECONDS:-90}
      PORT: 8080
    ports:
      - "${OPENWEBUI_ADAPTER_PORT:-8090}:8080"
    networks:
      - ai-stack-network
    depends_on:
      - langgraph-agents

networks:
  ai-stack-network:
    external: true
    name: ai-stack-network
