# LangGraph Multi-Agent System

A sophisticated multi-agent system built with LangGraph, featuring specialized agents for food management, task tracking, and calendar events. Implements intelligent routing, seamless handoffs, and Redis-based state persistence.

## üéØ Features

### Core Capabilities
- **Multi-Agent Architecture**: Three specialized agents (Food, Task, Event) with domain expertise
- **Hybrid Routing**: Fast keyword-based routing with LLM fallback for complex queries
- **Intelligent Handoffs**: Automatic domain detection and context-preserving agent transitions
- **State Management**: Redis-based persistence with automatic pruning
- **Flexible LLM Support**: Easy switching between Ollama and OpenAI-compatible providers
- **Hybrid Search**: Combined database queries and vector search for intelligent recommendations

### Agent Specializations

#### üçΩÔ∏è Food Agent
- Food logging with full context
- Meal suggestions based on history and preferences
- Dietary pattern analysis
- Hybrid recommendations (DB + vector search)
- Shopping list generation

#### ‚úÖ Task Agent
- Task creation and management
- Priority and deadline tracking
- Project breakdown assistance
- Productivity planning
- Task status updates

#### üìÖ Event Agent
- Calendar event management
- Schedule conflict detection
- Available time slot suggestions
- Time blocking support
- Meeting coordination

## üèóÔ∏è Architecture

```
                   User Request
                        ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  Hybrid Router  ‚îÇ
              ‚îÇ (Keywords + LLM)‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚Üì              ‚Üì              ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ  Food  ‚îÇ    ‚îÇ  Task  ‚îÇ    ‚îÇ Event  ‚îÇ
   ‚îÇ Agent  ‚îÇ    ‚îÇ Agent  ‚îÇ    ‚îÇ Agent  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ             ‚îÇ              ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ   Tools     ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚Üì         ‚Üì              ‚Üì
    PostgreSQL  Qdrant         n8n
```

### Key Components

**State Management**
- Redis-based checkpointing for conversation persistence
- Automatic state pruning (configurable message limit)
- Domain-specific contexts shared across agents
- 24-hour TTL (configurable)

**Routing Strategy**
- **Simple queries**: Direct keyword matching (fast)
- **Complex queries**: LLM-based routing (accurate)
- **Handoffs**: Automatic domain shift detection

**Tool Layer**
- **Database Tools**: Direct SQL queries for structured data
- **Vector Tools**: Qdrant semantic search
- **Hybrid Tools**: Combined DB + vector for recommendations
- **n8n Integration**: Workflow triggers and embeddings

## üöÄ Quick Start

### Prerequisites

- Docker and Docker Compose
- PostgreSQL database
- Redis (included in docker-compose)
- Qdrant vector database
- Ollama (for local LLM) or OpenAI API key

### Installation

1. **Clone and navigate to directory**
```bash
cd containers/langgraph-agents
```

2. **Configure environment**
```bash
cp .env.example .env
# Edit .env with your settings
```

3. **Build and run**
```bash
docker-compose up --build
```

The service will be available at `http://localhost:8000`

### Configuration

#### LLM Provider: Ollama (Local)
```env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=llama3.2:3b
```

#### LLM Provider: OpenAI-Compatible
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=your-api-key
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4
```

#### State Management
```env
STATE_PRUNING_ENABLED=true
STATE_MAX_MESSAGES=20
STATE_TTL_SECONDS=86400
```

## üì° API Usage

### Chat Endpoint

```bash
POST /chat
```

**Request:**
```json
{
  "message": "Suggest something to eat",
  "user_id": "user123",
  "workspace": "default",
  "session_id": "session-abc-123"
}
```

**Response:**
```json
{
  "response": "Based on your history, I'd suggest...",
  "agent": "food_agent",
  "session_id": "session-abc-123",
  "turn_count": 1,
  "timestamp": "2025-11-19T10:30:00Z"
}
```

### Session Management

**Get Session Info:**
```bash
GET /session/{session_id}
```

**Delete Session:**
```bash
DELETE /session/{session_id}
```

### Health Check

```bash
GET /health
```

## üîÑ Agent Handoff Examples

### Food ‚Üí Task
```
User: "Suggest something to eat"
Food Agent: "How about Thai curry? You rated it 5/5 last time."
User: "Great! Create a task to buy ingredients"
Food Agent: "I'll hand this to the Task Agent..."
Task Agent: "I'll create a grocery task for Thai curry ingredients."
```

### Task ‚Üí Event
```
User: "Show me my tasks"
Task Agent: "You have 3 high-priority tasks..."
User: "Schedule time to work on them"
Task Agent: "Connecting you with the Event Agent..."
Event Agent: "Let me check your calendar for available time..."
```

## üõ†Ô∏è Development

### Project Structure

```
langgraph-agents/
‚îú‚îÄ‚îÄ main.py                 # FastAPI application
‚îú‚îÄ‚îÄ config.py               # Configuration management
‚îú‚îÄ‚îÄ requirements.txt        # Dependencies
‚îú‚îÄ‚îÄ Dockerfile             # Container definition
‚îú‚îÄ‚îÄ docker-compose.yml     # Service orchestration
‚îÇ
‚îú‚îÄ‚îÄ graph/
‚îÇ   ‚îú‚îÄ‚îÄ state.py           # State schema & pruning
‚îÇ   ‚îú‚îÄ‚îÄ workflow.py        # LangGraph workflow
‚îÇ   ‚îú‚îÄ‚îÄ routing.py         # Hybrid routing logic
‚îÇ   ‚îî‚îÄ‚îÄ checkpointer.py    # Redis persistence
‚îÇ
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ base.py            # Base agent utilities
‚îÇ   ‚îú‚îÄ‚îÄ food_agent.py      # Food specialist
‚îÇ   ‚îú‚îÄ‚îÄ task_agent.py      # Task specialist
‚îÇ   ‚îî‚îÄ‚îÄ event_agent.py     # Event specialist
‚îÇ
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ database.py        # Direct DB queries
‚îÇ   ‚îú‚îÄ‚îÄ vector.py          # Qdrant search
‚îÇ   ‚îú‚îÄ‚îÄ hybrid.py          # Combined tools
‚îÇ   ‚îî‚îÄ‚îÄ n8n.py            # Workflow integration
‚îÇ
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îú‚îÄ‚îÄ food_agent.txt     # Food agent system prompt
‚îÇ   ‚îú‚îÄ‚îÄ task_agent.txt     # Task agent system prompt
‚îÇ   ‚îî‚îÄ‚îÄ event_agent.txt    # Event agent system prompt
‚îÇ
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ llm.py             # LLM factory
    ‚îú‚îÄ‚îÄ db.py              # Database connection
    ‚îú‚îÄ‚îÄ redis_client.py    # Redis client
    ‚îî‚îÄ‚îÄ logging.py         # Logging setup
```

### Running Locally

```bash
# Install dependencies
pip install -r requirements.txt

# Set environment variables
export LLM_PROVIDER=ollama
export OLLAMA_BASE_URL=http://localhost:11434
# ... other vars

# Run application
python main.py
```

### Testing

```bash
# Install dev dependencies
pip install pytest pytest-asyncio

# Run tests
pytest
```

## üîß Customization

### Adding a New Agent

1. **Create system prompt**
```bash
touch prompts/memory_agent.txt
```

2. **Implement agent**
```python
# agents/memory_agent.py
from .base import load_system_prompt, create_agent_prompt

MEMORY_AGENT_PROMPT = load_system_prompt("memory_agent")
MEMORY_TOOLS = [...]

async def memory_agent_node(state: MultiAgentState) -> Dict[str, Any]:
    # Implementation
    pass
```

3. **Add to workflow**
```python
# graph/workflow.py
workflow.add_node("memory_agent", memory_agent_node)
```

4. **Update routing**
```python
# graph/routing.py
MEMORY_KEYWORDS = ["remember", "note", "search"]
```

### Switching LLM Models

Simply update the `.env` file:

```env
# Switch to different Ollama model
OLLAMA_MODEL=llama3.1:8b

# Or switch to OpenAI
LLM_PROVIDER=openai
OPENAI_MODEL=gpt-4-turbo
```

No code changes required!

## üìä Performance

### Design Decisions

**State Pruning** ‚úÖ Implemented
- Keeps last N messages (default: 20)
- Prevents state bloat
- Maintains conversation context

**Domain Boundary Detection** ‚úÖ Implemented
- Clear system prompts with domain definitions
- LLM-based handoff detection
- Explicit handoff keywords

**Hybrid Routing** ‚úÖ Implemented
- Fast keyword matching for simple queries
- LLM routing for complex cases
- Reduces unnecessary LLM calls

**Redis Persistence** ‚úÖ Implemented
- Persistent state across restarts
- Scalable to multiple instances
- Automatic TTL cleanup

### Future Optimizations

**Vector Search Speed** üîÑ Deferred
- Planned: Query caching
- Planned: Parallel DB + vector execution
- Planned: Result pre-computation

**LLM Call Reduction** üîÑ Deferred
- Planned: Routing decision caching
- Planned: Batch tool calls
- Planned: Smaller model for routing

## üîí Security

- Environment-based configuration
- No secrets in code
- Input validation with Pydantic
- User isolation via user_id
- Session-based state isolation

## üìö Resources

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [LangGraph Multi-Agent Tutorial](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/)
- [Implementation Plan](../../LANGGRAPH_MULTI_AGENT_PLAN.md)

## üêõ Troubleshooting

### Common Issues

**Connection to Ollama fails**
```bash
# Check Ollama is running
curl http://localhost:11434/api/tags

# Update OLLAMA_BASE_URL if needed
```

**Redis connection error**
```bash
# Check Redis is running
docker ps | grep redis

# Verify connection
redis-cli ping
```

**Database connection issues**
```bash
# Check PostgreSQL
docker ps | grep postgres

# Test connection
psql -h localhost -U postgres -d ai_assistant
```

**Agent not routing correctly**
- Check logs: `docker logs langgraph-agents`
- Review routing keywords in `graph/routing.py`
- Verify system prompts are loaded

## üìù License

This project is part of the AI Assistant Local Stack.

## ü§ù Contributing

1. Follow existing code style
2. Add tests for new features
3. Update documentation
4. Test with both Ollama and OpenAI providers

---

**Built with ‚ù§Ô∏è using LangGraph, FastAPI, and Redis**
